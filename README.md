# CourseGraph ğŸ“š

**Interactive 3D prerequisite graph for Cornell CS & Math courses with AI-powered course advisor**

CourseGraph visualizes course prerequisites as an interactive 3D knowledge graph, enriched with student sentiment data from Reddit and powered by Google Gemini AI for intelligent course planning.

---

## ğŸ¯ Features

### Currently Implemented (MVP)
- âœ… **Cornell API Scraper** - Fetches 158 CS + Math courses
- âœ… **Reddit Sentiment Analysis** - VADER NLP for difficulty & enjoyment scores
- âœ… **NetworkX Graph** - Prerequisite chains with 158 nodes
- âœ… **FastAPI Backend** - `/api/graph` and `/api/chat` endpoints
- âœ… **Gemini AI Integration** - Prerequisite parsing & course advisor chatbot

### Coming Soon
- ğŸš§ **3D Visualization** - ForceGraph3D with sentiment-based styling
- ğŸš§ **Interactive Chat** - RAG-based course planning assistant
- ğŸš§ **Course Details Panel** - Click nodes to see sentiment data

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- Node.js 18+
- Gemini API key (optional, for AI features)
- Reddit API credentials (optional, for sentiment analysis)

### Backend Setup

```bash
# Navigate to backend
cd backend

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your API keys (optional)

# Run data pipeline (uses regex fallback without API keys)
python scripts/scraper.py          # Fetch courses (2 seconds)
python scripts/reddit_scraper.py   # Scrape Reddit (optional, requires API key)
python scripts/sentiment_analyzer.py  # Generate sentiment scores
python scripts/build_graph.py      # Build NetworkX graph

# Start backend server
python -m uvicorn app.main:app --port 8000
```

**Backend will be available at:** `http://localhost:8000`

### API Endpoints

```bash
# Health check
curl http://localhost:8000/

# Get course graph (158 CS + Math courses)
curl http://localhost:8000/api/graph

# Chat with AI advisor (requires Gemini API key)
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What prerequisites do I need for CS 4820?"}'
```

---

## ğŸ“ Project Structure

```
coursegraph/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ scraper.py              # Cornell API scraper âœ…
â”‚   â”‚   â”œâ”€â”€ reddit_scraper.py       # Reddit sentiment scraper âœ…
â”‚   â”‚   â”œâ”€â”€ sentiment_analyzer.py   # VADER NLP analysis âœ…
â”‚   â”‚   â””â”€â”€ build_graph.py          # NetworkX graph builder âœ…
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI application âœ…
â”‚   â”‚   â”œâ”€â”€ config/settings.py      # Environment config âœ…
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ graph.py            # GET /api/graph âœ…
â”‚   â”‚   â”‚   â””â”€â”€ chat.py             # POST /api/chat âœ…
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ gemini_service.py   # Gemini API wrapper âœ…
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw_courses.json        # 158 courses (generated) âœ…
â”‚   â”‚   â”œâ”€â”€ reddit_comments.json    # Sentiment data (optional)
â”‚   â”‚   â”œâ”€â”€ sentiment_scores.json   # Difficulty/enjoyment scores
â”‚   â”‚   â””â”€â”€ graph_data.json         # NetworkX graph âœ…
â”‚   â””â”€â”€ requirements.txt            # Python dependencies âœ…
â”‚
â””â”€â”€ frontend/                       # Next.js app (ğŸš§ coming soon)
    â””â”€â”€ (To be implemented)
```

---

## ğŸ”§ Configuration

### Environment Variables

Create `backend/.env` with:

```env
# Gemini API (get from https://aistudio.google.com/app/apikey)
GEMINI_API_KEY=your_key_here

# Reddit API (create app at https://www.reddit.com/prefs/apps)
REDDIT_CLIENT_ID=your_client_id
REDDIT_CLIENT_SECRET=your_client_secret
REDDIT_USER_AGENT=CourseGraph:v1.0

# Backend config
CORS_ORIGINS=["http://localhost:3000"]
CORNELL_ROSTER_SEMESTER=FA25
```

**Note:** The app works without API keys using fallback methods:
- **Without Gemini:** Uses regex for prerequisite parsing
- **Without Reddit:** Uses neutral sentiment scores (5.0/10)

---

## ğŸ“Š Current Status

**Data Pipeline:** âœ… Complete
- Scraped **158 courses** (97 CS + 61 MATH)
- Graph built with 158 nodes
- Ready for visualization

**Backend API:** âœ… Running
- FastAPI server operational
- Graph endpoint serving data
- Chat endpoint ready (needs Gemini key)

**Frontend:** ğŸš§ In Progress
- Next.js setup needed
- 3D visualization planned
- UI components designed

---

## ğŸ§ª Testing

```bash
# Test scraper
cd backend
python scripts/scraper.py

# Verify graph data
ls -lh data/
# Should see: raw_courses.json (~105 KB), graph_data.json (~125 KB)

# Test API
curl http://localhost:8000/api/graph | jq '.nodes | length'
# Expected: 158
```

---

## ğŸ›£ï¸ Roadmap

- [x] Cornell API scraper
- [x] Reddit sentiment analysis
- [x] NetworkX graph builder
- [x] FastAPI backend
- [x] Gemini AI integration
- [ ] Next.js frontend
- [ ] 3D ForceGraph visualization
- [ ] Interactive chat UI
- [ ] Course details panel
- [ ] Sentiment-based node styling
- [ ] RAG enhancement for chat

---

## ğŸ“ Tech Stack

**Backend:**
- FastAPI (Python web framework)
- NetworkX (graph algorithms)
- Google Gemini AI (prerequisite parsing & chat)
- VADER (sentiment analysis)
- PRAW (Reddit API)

**Frontend (Planned):**
- Next.js 14 (React framework)
- react-force-graph-3d (3D visualization)
- Tailwind CSS (styling)
- Axios (API client)

---

## ğŸ¤ Contributing

This is a Cornell-specific educational project. Contributions welcome!

---

## ğŸ“„ License

MIT License

---

**Built for Cornell students by students** ğŸ“
